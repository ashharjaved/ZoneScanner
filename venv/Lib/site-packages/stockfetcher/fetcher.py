#!/usr/bin/env python3
"""
Stock Sector Metadata Collector (Refactored with Shariah Compliance and Sector Filtering)
Author: Ashhar Javed
Updated: 2025-07-14
"""

from __future__ import annotations
import argparse
import csv
import logging
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from io import StringIO
from pathlib import Path
from typing import Dict, List

import pandas as pd
import requests
import yfinance as yf
from requests.adapters import HTTPAdapter, Retry

# ---------------------------------- Config ----------------------------------
NSE_EQUITY_URL = "https://nsearchives.nseindia.com/content/equities/EQUITY_L.csv"
#BSE_EQUITY_URL = "https://api.bseindia.com/BseIndiaAPI/api/GetScripMaster/w?strType=Equity"
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/137.0.0.0 Safari/537.36"
    ),
    "Accept-Encoding": "gzip, deflate",
}
THREADS = min(32, (os.cpu_count() or 2) * 5)
RETRY_STRATEGY = Retry(total=3, backoff_factor=0.5, status_forcelist=(500, 502, 503, 504))
NON_ISLAMIC_INDUSTRIES = [
    'Banks', 'Banking', 'Insurance', 'Alcoholic Beverages', 'Tobacco', 'Gambling',
    'Casinos', 'Adult Entertainment', 'Weapons', 'Defense', 'Financial Services',
    'Investment Banking', 'Real Estate', 'Music', 'Movies', 'Airlines', 'Hotels'
]

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
logger = logging.getLogger("StockFetcher")

# ----------------------------- Main Fetcher Class ----------------------------
class StockFetcher:
    def __init__(self, sectors: List[str] | None = None, exchange: str = "nse"):
        self.sectors = [s.lower() for s in sectors] if sectors else None
        self.exchange = exchange.lower()
        self.session = self._create_session()

    def _create_session(self) -> requests.Session:
        session = requests.Session()
        session.headers.update(HEADERS)
        adapter = HTTPAdapter(max_retries=RETRY_STRATEGY)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session
        
    def add_metadata(self, df):
        logger.info("📊 Enriching data with sector/industry from Yahoo Finance…")
        meta = []
        for symbol in df["YahooSymbol"]:
            try:
                ticker = yf.Ticker(symbol)
                info = ticker.info
                meta.append({
                    "YahooSymbol": symbol,
                    "Sector": info.get("sector", None),
                    "Industry": info.get("industry", None)
                })
            except Exception as e:
                logger.warning(f"⚠️ Could not fetch info for {symbol}: {e}")
                meta.append({
                    "YahooSymbol": symbol,
                    "Sector": None,
                    "Industry": None
                })
        meta_df = pd.DataFrame(meta)
    
        # ✅ This prevents column suffixes (_x, _y)
        return df.merge(meta_df, on="YahooSymbol", how="left", suffixes=('', '_meta'))
        
    def fetch_exchange_symbols(self, limit: int | None = None) -> pd.DataFrame:
        dfs = []
        if self.exchange in ["nse"]:
            dfs.append(self._fetch_nse_symbols(limit))
        #if self.exchange in ["bse", "both"]:
         #   dfs.append(self._fetch_bse_symbols(limit))
        if not dfs:
            raise ValueError("Invalid exchange mode. Choose from 'nse', 'bse', 'both'.")
        return pd.concat(dfs, ignore_index=True)

    def _fetch_nse_symbols(self, limit):
        logger.info("Fetching NSE symbols …")
        response = self.session.get(NSE_EQUITY_URL, timeout=10)
        response.raise_for_status()
        if "DOCTYPE html" in response.text[:100]:
            raise ValueError("NSE returned HTML instead of CSV.")

        df = pd.read_csv(StringIO(response.text), engine="python", sep=",", encoding="utf-8", dtype=str, on_bad_lines="skip", quoting=csv.QUOTE_NONE)
        df.columns = [col.strip().upper() for col in df.columns]

        df = df[df["SERIES"].isin(["EQ", "BE"])]
        df = df.dropna(subset=["SYMBOL"]).copy().reset_index(drop=True)
        df["SYMBOL"] = df["SYMBOL"].astype(str).str.strip() + ".NS"

        df["EXCHANGE"] = "NSE"
        df = df[["SYMBOL", "SERIES", "DATE OF LISTING", "ISIN NUMBER", "FACE VALUE", "EXCHANGE"]]

        return df.head(limit) if limit else df

    def _fetch_bse_symbols(self, limit):
        logger.info("Fetching BSE symbols …")
        response = self.session.get(BSE_EQUITY_URL, timeout=10)
        response.raise_for_status()
        json_data = response.json()
        records = json_data.get("Table", [])
        df = pd.DataFrame(records)

        df = df.rename(columns={"Scrip_Id": "SYMBOL"})
        df = df.dropna(subset=["SYMBOL"])
        df["SYMBOL"] = df["SYMBOL"].astype(str).str.strip() + ".BO"

        df["SERIES"] = "EQ"
        df["DATE OF LISTING"] = None
        df["ISIN NUMBER"] = None
        df["FACE VALUE"] = None
        df["EXCHANGE"] = "BSE"

        return df[["SYMBOL", "SERIES", "DATE OF LISTING", "ISIN NUMBER", "FACE VALUE", "EXCHANGE"]].head(limit) if limit else df

    def fetch_yahoo_metadata(self, symbol: str) -> Dict[str, str]:
        try:
            info = yf.Ticker(symbol).info
            return {
                "Symbol": symbol.replace(".NS", ""),
                #"Symbol": symbol.replace(".NS", "").replace(".BO", ""),
                "YahooSymbol": symbol,
                "Company": info.get("longName") or info.get("shortName") or "N/A",
                "Sector": info.get("sector", "N/A"),
                "Industry": info.get("industry", "N/A"),
            }
        except Exception as e:
            logger.warning("Failed %s – %s", symbol, e)
            return {
                "Symbol": symbol.replace(".NS", ""),
                "YahooSymbol": symbol,
                "Company": "N/A",
                "Sector": "N/A",
                "Industry": "N/A",
            }

    def _fetch_shariah_metadata(self, symbol: str) -> Dict[str, str] | None:
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            industry = info.get("industry", "").lower()
            if any(bad.lower() in industry for bad in NON_ISLAMIC_INDUSTRIES):
                return None

            market_cap = info.get("marketCap", 0)
            total_debt = info.get("totalDebt", 0)
            if not market_cap or not total_debt:
                return None

            if total_debt / market_cap > 0.33:
                return None

            return {
                "YahooSymbol": symbol,
                "Symbol": symbol.replace(".NS", ""),
                "Company": info.get("longName") or info.get("shortName", "N/A"),
                "Sector": info.get("sector", "N/A"),
                "Industry": info.get("industry", "N/A"),
            }
        except Exception as e:
            logger.warning("Skipping %s – %s", symbol, e)
            return None

    def collect_data(self, nse_limit: int | None = None, mode: str = "shariah") -> pd.DataFrame:
        base_df = self.fetch_exchange_symbols(limit=nse_limit)
        if base_df.empty:
            return pd.DataFrame()

        base_df["YahooSymbol"] = base_df["SYMBOL"]
        base_df["Symbol"] = base_df["SYMBOL"].str.replace(".NS", "", regex=False)
        #base_df["Symbol"] = base_df["SYMBOL"].str.replace(".NS", "", regex=False).str.replace(".BO", "", regex=False)

        if mode == "basic":
            base_df["Company"] = "N/A"
            base_df["Sector"] = "N/A"
            base_df["Industry"] = "N/A"
            return base_df[["SYMBOL", "SERIES", "DATE OF LISTING", "ISIN NUMBER", "FACE VALUE", "YahooSymbol", "Symbol", "Company","Sector","Industry","EXCHANGE"]].reset_index(drop=True)

        symbols = base_df["YahooSymbol"].tolist()
        rows = []

        fetch_fn = self._fetch_shariah_metadata if mode == "shariah" else self.fetch_yahoo_metadata

        logger.info(f"Fetching metadata in '{mode}' mode …")
        with ThreadPoolExecutor(max_workers=THREADS) as executor:
            futures = {executor.submit(fetch_fn, s): s for s in symbols}
            for f in as_completed(futures):
                result = f.result()
                if result:
                    rows.append(result)

        if not rows:
            logger.warning("No metadata found.")
            return pd.DataFrame()

        meta_df = pd.DataFrame(rows)
        merged_df = (
            base_df.merge(meta_df, on=["YahooSymbol", "Symbol"], how="inner")
            .sort_values("Symbol")
            .reset_index(drop=True)
        )

        if self.sectors:
            merged_df = self._apply_sector_filter(merged_df)

        return merged_df[["SYMBOL", "SERIES", "DATE OF LISTING", "ISIN NUMBER", "FACE VALUE",
                          "YahooSymbol", "Symbol", "Company", "Sector", "Industry", "EXCHANGE"]]

    def _apply_sector_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        logger.info("Applying sector filter: %s", ", ".join(self.sectors))
        return df[df["Sector"].str.lower().isin(self.sectors)]

    def save_to_files(self, df: pd.DataFrame, mode: str = "shariah") -> None:
        suffix = f"_{self.exchange}_{mode}"
        timestamp = time.strftime("%Y%m%d")
        out_csv = Path(f"nse_sectors{suffix}_{timestamp}.csv")
        df.to_csv(out_csv, index=False)
        logger.info("Saved %d records to %s", len(df), out_csv)